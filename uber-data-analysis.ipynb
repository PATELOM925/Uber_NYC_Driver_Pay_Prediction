{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4934375,"sourceType":"datasetVersion","datasetId":2861326}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-10T04:41:54.321466Z","iopub.execute_input":"2024-04-10T04:41:54.321827Z","iopub.status.idle":"2024-04-10T04:41:55.229463Z","shell.execute_reply.started":"2024-04-10T04:41:54.321801Z","shell.execute_reply":"2024-04-10T04:41:55.228575Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/uber-nyc-forhire-vehicles-trip-data-2021/fhvhv_tripdata_2021-02.parquet\n/kaggle/input/uber-nyc-forhire-vehicles-trip-data-2021/working_parquet_format.pdf\n/kaggle/input/uber-nyc-forhire-vehicles-trip-data-2021/data_dictionary_trip_records_hvfhs.pdf\n/kaggle/input/uber-nyc-forhire-vehicles-trip-data-2021/fhvhv_tripdata_2021-10.parquet\n/kaggle/input/uber-nyc-forhire-vehicles-trip-data-2021/fhvhv_tripdata_2021-05.parquet\n/kaggle/input/uber-nyc-forhire-vehicles-trip-data-2021/taxi_zone_lookup.csv\n/kaggle/input/uber-nyc-forhire-vehicles-trip-data-2021/fhvhv_tripdata_2021-06.parquet\n/kaggle/input/uber-nyc-forhire-vehicles-trip-data-2021/fhvhv_tripdata_2021-04.parquet\n/kaggle/input/uber-nyc-forhire-vehicles-trip-data-2021/fhvhv_tripdata_2021-09.parquet\n/kaggle/input/uber-nyc-forhire-vehicles-trip-data-2021/fhvhv_tripdata_2021-12.parquet\n/kaggle/input/uber-nyc-forhire-vehicles-trip-data-2021/fhvhv_tripdata_2021-08.parquet\n/kaggle/input/uber-nyc-forhire-vehicles-trip-data-2021/fhvhv_tripdata_2021-01.parquet\n/kaggle/input/uber-nyc-forhire-vehicles-trip-data-2021/fhvhv_tripdata_2021-03.parquet\n/kaggle/input/uber-nyc-forhire-vehicles-trip-data-2021/fhvhv_tripdata_2021-07.parquet\n/kaggle/input/uber-nyc-forhire-vehicles-trip-data-2021/nyc 2021-01-01 to 2021-12-31.csv\n/kaggle/input/uber-nyc-forhire-vehicles-trip-data-2021/fhvhv_tripdata_2021-11.parquet\n/kaggle/input/uber-nyc-forhire-vehicles-trip-data-2021/taxi_zones/taxi_zones.dbf\n/kaggle/input/uber-nyc-forhire-vehicles-trip-data-2021/taxi_zones/taxi_zones.shp.xml\n/kaggle/input/uber-nyc-forhire-vehicles-trip-data-2021/taxi_zones/taxi_zones.shp\n/kaggle/input/uber-nyc-forhire-vehicles-trip-data-2021/taxi_zones/taxi_zones.shx\n/kaggle/input/uber-nyc-forhire-vehicles-trip-data-2021/taxi_zones/taxi_zones.sbx\n/kaggle/input/uber-nyc-forhire-vehicles-trip-data-2021/taxi_zones/taxi_zones.sbn\n/kaggle/input/uber-nyc-forhire-vehicles-trip-data-2021/taxi_zones/taxi_zones.prj\n","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/uber-nyc-forhire-vehicles-trip-data-2021/nyc 2021-01-01 to 2021-12-31.csv')\ndata","metadata":{"execution":{"iopub.status.busy":"2024-04-10T04:42:02.913395Z","iopub.execute_input":"2024-04-10T04:42:02.914205Z","iopub.status.idle":"2024-04-10T04:42:02.980741Z","shell.execute_reply.started":"2024-04-10T04:42:02.914172Z","shell.execute_reply":"2024-04-10T04:42:02.979882Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"    name address              resolvedAddress    datetime  temp  feelslike  \\\n0    nyc     nyc  New York, NY, United States  2021-01-01   2.5       -0.2   \n1    nyc     nyc  New York, NY, United States  2021-01-02   5.8        3.6   \n2    nyc     nyc  New York, NY, United States  2021-01-03   2.5       -1.6   \n3    nyc     nyc  New York, NY, United States  2021-01-04   3.6        1.1   \n4    nyc     nyc  New York, NY, United States  2021-01-05   3.8        1.3   \n..   ...     ...                          ...         ...   ...        ...   \n360  nyc     nyc  New York, NY, United States  2021-12-27   2.7        0.4   \n361  nyc     nyc  New York, NY, United States  2021-12-28   5.9        4.3   \n362  nyc     nyc  New York, NY, United States  2021-12-29   5.9        3.8   \n363  nyc     nyc  New York, NY, United States  2021-12-30   7.8        7.0   \n364  nyc     nyc  New York, NY, United States  2021-12-31  10.3       10.2   \n\n     dew  humidity  precip  precipprob  ... snow  snowdepth  windgust  \\\n0   -3.0      67.8   15.33         100  ...  0.0        0.0       NaN   \n1    1.2      74.0    2.38         100  ...  1.9        0.6      54.6   \n2   -0.5      80.7    5.09         100  ...  1.2        1.7      42.2   \n3   -0.2      76.6    0.84         100  ...  0.5        0.7       NaN   \n4   -1.5      68.7    0.00           0  ...  0.0        0.1      31.7   \n..   ...       ...     ...         ...  ...  ...        ...       ...   \n360 -4.5      59.6    1.68         100  ...  0.0        0.0      25.9   \n361  0.8      71.6    0.53         100  ...  0.0        0.0       NaN   \n362  3.9      87.0    5.50         100  ...  0.0        0.0      25.9   \n363  5.8      87.1    1.52         100  ...  0.0        0.0       NaN   \n364  7.8      84.3    0.05         100  ...  0.0        0.0       NaN   \n\n     windspeed  winddir  sealevelpressure  cloudcover  visibility  uvindex  \\\n0         15.5     69.8            1028.9        50.6        14.0        3   \n1         25.5    246.9            1012.4        63.9        12.2        5   \n2         24.1     66.4            1017.0        81.5        13.2        1   \n3         17.3    141.1            1014.6        89.3        15.6        4   \n4         15.2    124.4            1013.1        98.8        16.0        2   \n..         ...      ...               ...         ...         ...      ...   \n360       17.2    116.3            1016.8        65.8        15.5        2   \n361       16.9    216.0            1010.6        76.4        13.7        2   \n362       19.9     52.0            1012.3       100.0         8.8        1   \n363        9.1     67.2            1013.7        98.8         8.4        2   \n364       12.0    223.0            1013.7        96.1        11.1        3   \n\n     severerisk  \n0           NaN  \n1           NaN  \n2           NaN  \n3           NaN  \n4           NaN  \n..          ...  \n360         NaN  \n361         NaN  \n362         NaN  \n363         NaN  \n364         NaN  \n\n[365 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>address</th>\n      <th>resolvedAddress</th>\n      <th>datetime</th>\n      <th>temp</th>\n      <th>feelslike</th>\n      <th>dew</th>\n      <th>humidity</th>\n      <th>precip</th>\n      <th>precipprob</th>\n      <th>...</th>\n      <th>snow</th>\n      <th>snowdepth</th>\n      <th>windgust</th>\n      <th>windspeed</th>\n      <th>winddir</th>\n      <th>sealevelpressure</th>\n      <th>cloudcover</th>\n      <th>visibility</th>\n      <th>uvindex</th>\n      <th>severerisk</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>nyc</td>\n      <td>nyc</td>\n      <td>New York, NY, United States</td>\n      <td>2021-01-01</td>\n      <td>2.5</td>\n      <td>-0.2</td>\n      <td>-3.0</td>\n      <td>67.8</td>\n      <td>15.33</td>\n      <td>100</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>15.5</td>\n      <td>69.8</td>\n      <td>1028.9</td>\n      <td>50.6</td>\n      <td>14.0</td>\n      <td>3</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>nyc</td>\n      <td>nyc</td>\n      <td>New York, NY, United States</td>\n      <td>2021-01-02</td>\n      <td>5.8</td>\n      <td>3.6</td>\n      <td>1.2</td>\n      <td>74.0</td>\n      <td>2.38</td>\n      <td>100</td>\n      <td>...</td>\n      <td>1.9</td>\n      <td>0.6</td>\n      <td>54.6</td>\n      <td>25.5</td>\n      <td>246.9</td>\n      <td>1012.4</td>\n      <td>63.9</td>\n      <td>12.2</td>\n      <td>5</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>nyc</td>\n      <td>nyc</td>\n      <td>New York, NY, United States</td>\n      <td>2021-01-03</td>\n      <td>2.5</td>\n      <td>-1.6</td>\n      <td>-0.5</td>\n      <td>80.7</td>\n      <td>5.09</td>\n      <td>100</td>\n      <td>...</td>\n      <td>1.2</td>\n      <td>1.7</td>\n      <td>42.2</td>\n      <td>24.1</td>\n      <td>66.4</td>\n      <td>1017.0</td>\n      <td>81.5</td>\n      <td>13.2</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>nyc</td>\n      <td>nyc</td>\n      <td>New York, NY, United States</td>\n      <td>2021-01-04</td>\n      <td>3.6</td>\n      <td>1.1</td>\n      <td>-0.2</td>\n      <td>76.6</td>\n      <td>0.84</td>\n      <td>100</td>\n      <td>...</td>\n      <td>0.5</td>\n      <td>0.7</td>\n      <td>NaN</td>\n      <td>17.3</td>\n      <td>141.1</td>\n      <td>1014.6</td>\n      <td>89.3</td>\n      <td>15.6</td>\n      <td>4</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>nyc</td>\n      <td>nyc</td>\n      <td>New York, NY, United States</td>\n      <td>2021-01-05</td>\n      <td>3.8</td>\n      <td>1.3</td>\n      <td>-1.5</td>\n      <td>68.7</td>\n      <td>0.00</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.1</td>\n      <td>31.7</td>\n      <td>15.2</td>\n      <td>124.4</td>\n      <td>1013.1</td>\n      <td>98.8</td>\n      <td>16.0</td>\n      <td>2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>360</th>\n      <td>nyc</td>\n      <td>nyc</td>\n      <td>New York, NY, United States</td>\n      <td>2021-12-27</td>\n      <td>2.7</td>\n      <td>0.4</td>\n      <td>-4.5</td>\n      <td>59.6</td>\n      <td>1.68</td>\n      <td>100</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>25.9</td>\n      <td>17.2</td>\n      <td>116.3</td>\n      <td>1016.8</td>\n      <td>65.8</td>\n      <td>15.5</td>\n      <td>2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>361</th>\n      <td>nyc</td>\n      <td>nyc</td>\n      <td>New York, NY, United States</td>\n      <td>2021-12-28</td>\n      <td>5.9</td>\n      <td>4.3</td>\n      <td>0.8</td>\n      <td>71.6</td>\n      <td>0.53</td>\n      <td>100</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>16.9</td>\n      <td>216.0</td>\n      <td>1010.6</td>\n      <td>76.4</td>\n      <td>13.7</td>\n      <td>2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>362</th>\n      <td>nyc</td>\n      <td>nyc</td>\n      <td>New York, NY, United States</td>\n      <td>2021-12-29</td>\n      <td>5.9</td>\n      <td>3.8</td>\n      <td>3.9</td>\n      <td>87.0</td>\n      <td>5.50</td>\n      <td>100</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>25.9</td>\n      <td>19.9</td>\n      <td>52.0</td>\n      <td>1012.3</td>\n      <td>100.0</td>\n      <td>8.8</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>363</th>\n      <td>nyc</td>\n      <td>nyc</td>\n      <td>New York, NY, United States</td>\n      <td>2021-12-30</td>\n      <td>7.8</td>\n      <td>7.0</td>\n      <td>5.8</td>\n      <td>87.1</td>\n      <td>1.52</td>\n      <td>100</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>9.1</td>\n      <td>67.2</td>\n      <td>1013.7</td>\n      <td>98.8</td>\n      <td>8.4</td>\n      <td>2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>364</th>\n      <td>nyc</td>\n      <td>nyc</td>\n      <td>New York, NY, United States</td>\n      <td>2021-12-31</td>\n      <td>10.3</td>\n      <td>10.2</td>\n      <td>7.8</td>\n      <td>84.3</td>\n      <td>0.05</td>\n      <td>100</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>12.0</td>\n      <td>223.0</td>\n      <td>1013.7</td>\n      <td>96.1</td>\n      <td>11.1</td>\n      <td>3</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>365 rows × 21 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Extract unique values from the 'Name' column of the DataFrame nyc_weather_2021\nx = data['address'].unique()\ny = data['name'].unique()\nz = data['resolvedAddress'].unique()\na = data['severerisk'].unique()\nb = data['precipprob'].unique()\nc = data['preciptype'].unique()\nprint(x,y,z,a,b,c)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T04:42:06.029001Z","iopub.execute_input":"2024-04-10T04:42:06.029803Z","iopub.status.idle":"2024-04-10T04:42:06.045237Z","shell.execute_reply.started":"2024-04-10T04:42:06.029770Z","shell.execute_reply":"2024-04-10T04:42:06.044248Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"['nyc'] ['nyc'] ['New York, NY, United States'] [nan] [100   0] ['rain' 'rain,snow' nan 'snow']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Thus the above indicates this 3 columns are of no use, as we know we are working with New York City Uber Trip Data.","metadata":{}},{"cell_type":"code","source":"# Drop unnecessary columns from the DataFrame nyc_weather_2021\ndata.drop(columns=['address', 'name', 'resolvedAddress','severerisk'], inplace=True)\ndata.columns","metadata":{"execution":{"iopub.status.busy":"2024-04-10T04:42:08.103964Z","iopub.execute_input":"2024-04-10T04:42:08.104641Z","iopub.status.idle":"2024-04-10T04:42:08.113386Z","shell.execute_reply.started":"2024-04-10T04:42:08.104608Z","shell.execute_reply":"2024-04-10T04:42:08.112370Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Index(['datetime', 'temp', 'feelslike', 'dew', 'humidity', 'precip',\n       'precipprob', 'preciptype', 'snow', 'snowdepth', 'windgust',\n       'windspeed', 'winddir', 'sealevelpressure', 'cloudcover', 'visibility',\n       'uvindex'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-04-10T04:42:08.241384Z","iopub.execute_input":"2024-04-10T04:42:08.241743Z","iopub.status.idle":"2024-04-10T04:42:08.250383Z","shell.execute_reply.started":"2024-04-10T04:42:08.241714Z","shell.execute_reply":"2024-04-10T04:42:08.249344Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"datetime              0\ntemp                  0\nfeelslike             0\ndew                   0\nhumidity              0\nprecip                0\nprecipprob            0\npreciptype          213\nsnow                  0\nsnowdepth             0\nwindgust             73\nwindspeed             0\nwinddir               0\nsealevelpressure      0\ncloudcover            0\nvisibility            0\nuvindex               0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"selected_columns = data[['snow', 'preciptype',\"precipprob\"]]\nselected_columns","metadata":{"execution":{"iopub.status.busy":"2024-04-10T04:42:08.378465Z","iopub.execute_input":"2024-04-10T04:42:08.379327Z","iopub.status.idle":"2024-04-10T04:42:08.391878Z","shell.execute_reply.started":"2024-04-10T04:42:08.379297Z","shell.execute_reply":"2024-04-10T04:42:08.391030Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"     snow preciptype  precipprob\n0     0.0       rain         100\n1     1.9       rain         100\n2     1.2  rain,snow         100\n3     0.5  rain,snow         100\n4     0.0        NaN           0\n..    ...        ...         ...\n360   0.0       rain         100\n361   0.0       rain         100\n362   0.0       rain         100\n363   0.0       rain         100\n364   0.0       rain         100\n\n[365 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>snow</th>\n      <th>preciptype</th>\n      <th>precipprob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>rain</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.9</td>\n      <td>rain</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.2</td>\n      <td>rain,snow</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.5</td>\n      <td>rain,snow</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>360</th>\n      <td>0.0</td>\n      <td>rain</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>361</th>\n      <td>0.0</td>\n      <td>rain</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>362</th>\n      <td>0.0</td>\n      <td>rain</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>363</th>\n      <td>0.0</td>\n      <td>rain</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>364</th>\n      <td>0.0</td>\n      <td>rain</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n<p>365 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\n# Assuming df is your DataFrame containing the weather data with the columns specified\n# Load your DataFrame, e.g., df = pd.read_csv('your_data.csv')\n\n# Select relevant columns for analysis\nselected_columns = ['temp', 'windspeed', 'winddir', 'sealevelpressure', 'cloudcover', 'visibility', 'windgust']\n\n# Create a new DataFrame with selected columns\nnyc_weather_2021_selected = data[selected_columns]\n\n# Drop rows with missing values\nnyc_weather_2021_selected.dropna(inplace=True)\n\n# Correlation analysis\ncorrelation_matrix = nyc_weather_2021_selected.corr()\nprint(\"Correlation Matrix:\")\nprint(correlation_matrix)\n\n# Split data into features (X) and target variable (y)\nX = nyc_weather_2021_selected.drop(columns=['windgust'])\ny = nyc_weather_2021_selected['windgust']\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Regression modeling\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Model evaluation\ntrain_score = model.score(X_train, y_train)\ntest_score = model.score(X_test, y_test)\nprint(\"\\nTraining R^2 score:\", train_score)\nprint(\"Testing R^2 score:\", test_score)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-10T04:42:08.530539Z","iopub.execute_input":"2024-04-10T04:42:08.531120Z","iopub.status.idle":"2024-04-10T04:42:09.781006Z","shell.execute_reply.started":"2024-04-10T04:42:08.531091Z","shell.execute_reply":"2024-04-10T04:42:09.779930Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Correlation Matrix:\n                      temp  windspeed   winddir  sealevelpressure  cloudcover  \\\ntemp              1.000000  -0.253595 -0.078479         -0.115677   -0.063462   \nwindspeed        -0.253595   1.000000  0.158710         -0.252771    0.054077   \nwinddir          -0.078479   0.158710  1.000000         -0.102958   -0.483563   \nsealevelpressure -0.115677  -0.252771 -0.102958          1.000000   -0.382584   \ncloudcover       -0.063462   0.054077 -0.483563         -0.382584    1.000000   \nvisibility        0.075165  -0.079636  0.451464          0.279185   -0.545779   \nwindgust         -0.002640   0.520714  0.206599         -0.348647    0.025295   \n\n                  visibility  windgust  \ntemp                0.075165 -0.002640  \nwindspeed          -0.079636  0.520714  \nwinddir             0.451464  0.206599  \nsealevelpressure    0.279185 -0.348647  \ncloudcover         -0.545779  0.025295  \nvisibility          1.000000 -0.065982  \nwindgust           -0.065982  1.000000  \n\nTraining R^2 score: 0.3735609182214302\nTesting R^2 score: 0.24144654472349458\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/27803129.py:15: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  nyc_weather_2021_selected.dropna(inplace=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"def fill_windgust_missing(df):\n    # Iterate through each row in the DataFrame\n    for index, row in df.iterrows():\n        # Check if WindGust value is missing\n        if pd.isnull(row['windgust']):\n            # Find the next non-null value in WindGust column\n            next_index = index + 1\n            while next_index < len(df) and pd.isnull(df.at[next_index, 'windgust']):\n                next_index += 1\n            if next_index < len(df):\n                next_windgust = df.at[next_index, 'windgust']\n                wind_speed = df.at[next_index, 'windspeed']\n                # Calculate ratio of next_windgust to wind_speed\n                if wind_speed != 0:\n                    ratio = next_windgust / wind_speed\n                    # Use the ratio to fill the missing WindGust value\n                    current_wind_speed = df.at[index,'windspeed']\n                    df.at[index, 'windgust'] = round(current_wind_speed * ratio, 2)\n                else:\n                    # If WindSpeed is 0, set WindGust to 0\n                    df.at[index, 'windgust'] = 0\n            else: \n                df.at[index, 'windgust'] = data['windgust'].fillna(method='ffill', inplace=True)\n\n    return df\n\nfill_windgust_missing(data)\nmedian_value = data['windgust'].median()\ndata['windgust'].fillna(median_value, inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-10T04:42:09.782682Z","iopub.execute_input":"2024-04-10T04:42:09.783099Z","iopub.status.idle":"2024-04-10T04:42:09.835191Z","shell.execute_reply.started":"2024-04-10T04:42:09.783073Z","shell.execute_reply":"2024-04-10T04:42:09.834113Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/292393658.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df.at[index, 'windgust'] = data['windgust'].fillna(method='ffill', inplace=True)\n/tmp/ipykernel_34/292393658.py:23: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  df.at[index, 'windgust'] = data['windgust'].fillna(method='ffill', inplace=True)\n/tmp/ipykernel_34/292393658.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df.at[index, 'windgust'] = data['windgust'].fillna(method='ffill', inplace=True)\n/tmp/ipykernel_34/292393658.py:23: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  df.at[index, 'windgust'] = data['windgust'].fillna(method='ffill', inplace=True)\n/tmp/ipykernel_34/292393658.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  data['windgust'].fillna(median_value, inplace=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-04-10T04:42:09.836412Z","iopub.execute_input":"2024-04-10T04:42:09.836742Z","iopub.status.idle":"2024-04-10T04:42:09.870147Z","shell.execute_reply.started":"2024-04-10T04:42:09.836716Z","shell.execute_reply":"2024-04-10T04:42:09.869177Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"       datetime  temp  feelslike  dew  humidity  precip  precipprob  \\\n0    2021-01-01   2.5       -0.2 -3.0      67.8   15.33         100   \n1    2021-01-02   5.8        3.6  1.2      74.0    2.38         100   \n2    2021-01-03   2.5       -1.6 -0.5      80.7    5.09         100   \n3    2021-01-04   3.6        1.1 -0.2      76.6    0.84         100   \n4    2021-01-05   3.8        1.3 -1.5      68.7    0.00           0   \n..          ...   ...        ...  ...       ...     ...         ...   \n360  2021-12-27   2.7        0.4 -4.5      59.6    1.68         100   \n361  2021-12-28   5.9        4.3  0.8      71.6    0.53         100   \n362  2021-12-29   5.9        3.8  3.9      87.0    5.50         100   \n363  2021-12-30   7.8        7.0  5.8      87.1    1.52         100   \n364  2021-12-31  10.3       10.2  7.8      84.3    0.05         100   \n\n    preciptype  snow  snowdepth  windgust  windspeed  winddir  \\\n0         rain   0.0        0.0     33.19       15.5     69.8   \n1         rain   1.9        0.6     54.60       25.5    246.9   \n2    rain,snow   1.2        1.7     42.20       24.1     66.4   \n3    rain,snow   0.5        0.7     36.08       17.3    141.1   \n4          NaN   0.0        0.1     31.70       15.2    124.4   \n..         ...   ...        ...       ...        ...      ...   \n360       rain   0.0        0.0     25.90       17.2    116.3   \n361       rain   0.0        0.0     22.00       16.9    216.0   \n362       rain   0.0        0.0     25.90       19.9     52.0   \n363       rain   0.0        0.0     25.90        9.1     67.2   \n364       rain   0.0        0.0     40.20       12.0    223.0   \n\n     sealevelpressure  cloudcover  visibility  uvindex  \n0              1028.9        50.6        14.0        3  \n1              1012.4        63.9        12.2        5  \n2              1017.0        81.5        13.2        1  \n3              1014.6        89.3        15.6        4  \n4              1013.1        98.8        16.0        2  \n..                ...         ...         ...      ...  \n360            1016.8        65.8        15.5        2  \n361            1010.6        76.4        13.7        2  \n362            1012.3       100.0         8.8        1  \n363            1013.7        98.8         8.4        2  \n364            1013.7        96.1        11.1        3  \n\n[365 rows x 17 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>datetime</th>\n      <th>temp</th>\n      <th>feelslike</th>\n      <th>dew</th>\n      <th>humidity</th>\n      <th>precip</th>\n      <th>precipprob</th>\n      <th>preciptype</th>\n      <th>snow</th>\n      <th>snowdepth</th>\n      <th>windgust</th>\n      <th>windspeed</th>\n      <th>winddir</th>\n      <th>sealevelpressure</th>\n      <th>cloudcover</th>\n      <th>visibility</th>\n      <th>uvindex</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-01-01</td>\n      <td>2.5</td>\n      <td>-0.2</td>\n      <td>-3.0</td>\n      <td>67.8</td>\n      <td>15.33</td>\n      <td>100</td>\n      <td>rain</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>33.19</td>\n      <td>15.5</td>\n      <td>69.8</td>\n      <td>1028.9</td>\n      <td>50.6</td>\n      <td>14.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-01-02</td>\n      <td>5.8</td>\n      <td>3.6</td>\n      <td>1.2</td>\n      <td>74.0</td>\n      <td>2.38</td>\n      <td>100</td>\n      <td>rain</td>\n      <td>1.9</td>\n      <td>0.6</td>\n      <td>54.60</td>\n      <td>25.5</td>\n      <td>246.9</td>\n      <td>1012.4</td>\n      <td>63.9</td>\n      <td>12.2</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-01-03</td>\n      <td>2.5</td>\n      <td>-1.6</td>\n      <td>-0.5</td>\n      <td>80.7</td>\n      <td>5.09</td>\n      <td>100</td>\n      <td>rain,snow</td>\n      <td>1.2</td>\n      <td>1.7</td>\n      <td>42.20</td>\n      <td>24.1</td>\n      <td>66.4</td>\n      <td>1017.0</td>\n      <td>81.5</td>\n      <td>13.2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-01-04</td>\n      <td>3.6</td>\n      <td>1.1</td>\n      <td>-0.2</td>\n      <td>76.6</td>\n      <td>0.84</td>\n      <td>100</td>\n      <td>rain,snow</td>\n      <td>0.5</td>\n      <td>0.7</td>\n      <td>36.08</td>\n      <td>17.3</td>\n      <td>141.1</td>\n      <td>1014.6</td>\n      <td>89.3</td>\n      <td>15.6</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-01-05</td>\n      <td>3.8</td>\n      <td>1.3</td>\n      <td>-1.5</td>\n      <td>68.7</td>\n      <td>0.00</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.1</td>\n      <td>31.70</td>\n      <td>15.2</td>\n      <td>124.4</td>\n      <td>1013.1</td>\n      <td>98.8</td>\n      <td>16.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>360</th>\n      <td>2021-12-27</td>\n      <td>2.7</td>\n      <td>0.4</td>\n      <td>-4.5</td>\n      <td>59.6</td>\n      <td>1.68</td>\n      <td>100</td>\n      <td>rain</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>25.90</td>\n      <td>17.2</td>\n      <td>116.3</td>\n      <td>1016.8</td>\n      <td>65.8</td>\n      <td>15.5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>361</th>\n      <td>2021-12-28</td>\n      <td>5.9</td>\n      <td>4.3</td>\n      <td>0.8</td>\n      <td>71.6</td>\n      <td>0.53</td>\n      <td>100</td>\n      <td>rain</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>22.00</td>\n      <td>16.9</td>\n      <td>216.0</td>\n      <td>1010.6</td>\n      <td>76.4</td>\n      <td>13.7</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>362</th>\n      <td>2021-12-29</td>\n      <td>5.9</td>\n      <td>3.8</td>\n      <td>3.9</td>\n      <td>87.0</td>\n      <td>5.50</td>\n      <td>100</td>\n      <td>rain</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>25.90</td>\n      <td>19.9</td>\n      <td>52.0</td>\n      <td>1012.3</td>\n      <td>100.0</td>\n      <td>8.8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>363</th>\n      <td>2021-12-30</td>\n      <td>7.8</td>\n      <td>7.0</td>\n      <td>5.8</td>\n      <td>87.1</td>\n      <td>1.52</td>\n      <td>100</td>\n      <td>rain</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>25.90</td>\n      <td>9.1</td>\n      <td>67.2</td>\n      <td>1013.7</td>\n      <td>98.8</td>\n      <td>8.4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>364</th>\n      <td>2021-12-31</td>\n      <td>10.3</td>\n      <td>10.2</td>\n      <td>7.8</td>\n      <td>84.3</td>\n      <td>0.05</td>\n      <td>100</td>\n      <td>rain</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.20</td>\n      <td>12.0</td>\n      <td>223.0</td>\n      <td>1013.7</td>\n      <td>96.1</td>\n      <td>11.1</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>365 rows × 17 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#filling missing preciptype with \"clear\" weather as whenever the preciprob is 0, it has Nan in preciptype column\nweather = 'clear'\ndata['preciptype'].fillna(weather, inplace=True)\ndata","metadata":{"execution":{"iopub.status.busy":"2024-04-10T04:42:09.872738Z","iopub.execute_input":"2024-04-10T04:42:09.873170Z","iopub.status.idle":"2024-04-10T04:42:09.905783Z","shell.execute_reply.started":"2024-04-10T04:42:09.873138Z","shell.execute_reply":"2024-04-10T04:42:09.904670Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/666438500.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  data['preciptype'].fillna(weather, inplace=True)\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"       datetime  temp  feelslike  dew  humidity  precip  precipprob  \\\n0    2021-01-01   2.5       -0.2 -3.0      67.8   15.33         100   \n1    2021-01-02   5.8        3.6  1.2      74.0    2.38         100   \n2    2021-01-03   2.5       -1.6 -0.5      80.7    5.09         100   \n3    2021-01-04   3.6        1.1 -0.2      76.6    0.84         100   \n4    2021-01-05   3.8        1.3 -1.5      68.7    0.00           0   \n..          ...   ...        ...  ...       ...     ...         ...   \n360  2021-12-27   2.7        0.4 -4.5      59.6    1.68         100   \n361  2021-12-28   5.9        4.3  0.8      71.6    0.53         100   \n362  2021-12-29   5.9        3.8  3.9      87.0    5.50         100   \n363  2021-12-30   7.8        7.0  5.8      87.1    1.52         100   \n364  2021-12-31  10.3       10.2  7.8      84.3    0.05         100   \n\n    preciptype  snow  snowdepth  windgust  windspeed  winddir  \\\n0         rain   0.0        0.0     33.19       15.5     69.8   \n1         rain   1.9        0.6     54.60       25.5    246.9   \n2    rain,snow   1.2        1.7     42.20       24.1     66.4   \n3    rain,snow   0.5        0.7     36.08       17.3    141.1   \n4        clear   0.0        0.1     31.70       15.2    124.4   \n..         ...   ...        ...       ...        ...      ...   \n360       rain   0.0        0.0     25.90       17.2    116.3   \n361       rain   0.0        0.0     22.00       16.9    216.0   \n362       rain   0.0        0.0     25.90       19.9     52.0   \n363       rain   0.0        0.0     25.90        9.1     67.2   \n364       rain   0.0        0.0     40.20       12.0    223.0   \n\n     sealevelpressure  cloudcover  visibility  uvindex  \n0              1028.9        50.6        14.0        3  \n1              1012.4        63.9        12.2        5  \n2              1017.0        81.5        13.2        1  \n3              1014.6        89.3        15.6        4  \n4              1013.1        98.8        16.0        2  \n..                ...         ...         ...      ...  \n360            1016.8        65.8        15.5        2  \n361            1010.6        76.4        13.7        2  \n362            1012.3       100.0         8.8        1  \n363            1013.7        98.8         8.4        2  \n364            1013.7        96.1        11.1        3  \n\n[365 rows x 17 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>datetime</th>\n      <th>temp</th>\n      <th>feelslike</th>\n      <th>dew</th>\n      <th>humidity</th>\n      <th>precip</th>\n      <th>precipprob</th>\n      <th>preciptype</th>\n      <th>snow</th>\n      <th>snowdepth</th>\n      <th>windgust</th>\n      <th>windspeed</th>\n      <th>winddir</th>\n      <th>sealevelpressure</th>\n      <th>cloudcover</th>\n      <th>visibility</th>\n      <th>uvindex</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-01-01</td>\n      <td>2.5</td>\n      <td>-0.2</td>\n      <td>-3.0</td>\n      <td>67.8</td>\n      <td>15.33</td>\n      <td>100</td>\n      <td>rain</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>33.19</td>\n      <td>15.5</td>\n      <td>69.8</td>\n      <td>1028.9</td>\n      <td>50.6</td>\n      <td>14.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-01-02</td>\n      <td>5.8</td>\n      <td>3.6</td>\n      <td>1.2</td>\n      <td>74.0</td>\n      <td>2.38</td>\n      <td>100</td>\n      <td>rain</td>\n      <td>1.9</td>\n      <td>0.6</td>\n      <td>54.60</td>\n      <td>25.5</td>\n      <td>246.9</td>\n      <td>1012.4</td>\n      <td>63.9</td>\n      <td>12.2</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-01-03</td>\n      <td>2.5</td>\n      <td>-1.6</td>\n      <td>-0.5</td>\n      <td>80.7</td>\n      <td>5.09</td>\n      <td>100</td>\n      <td>rain,snow</td>\n      <td>1.2</td>\n      <td>1.7</td>\n      <td>42.20</td>\n      <td>24.1</td>\n      <td>66.4</td>\n      <td>1017.0</td>\n      <td>81.5</td>\n      <td>13.2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-01-04</td>\n      <td>3.6</td>\n      <td>1.1</td>\n      <td>-0.2</td>\n      <td>76.6</td>\n      <td>0.84</td>\n      <td>100</td>\n      <td>rain,snow</td>\n      <td>0.5</td>\n      <td>0.7</td>\n      <td>36.08</td>\n      <td>17.3</td>\n      <td>141.1</td>\n      <td>1014.6</td>\n      <td>89.3</td>\n      <td>15.6</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-01-05</td>\n      <td>3.8</td>\n      <td>1.3</td>\n      <td>-1.5</td>\n      <td>68.7</td>\n      <td>0.00</td>\n      <td>0</td>\n      <td>clear</td>\n      <td>0.0</td>\n      <td>0.1</td>\n      <td>31.70</td>\n      <td>15.2</td>\n      <td>124.4</td>\n      <td>1013.1</td>\n      <td>98.8</td>\n      <td>16.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>360</th>\n      <td>2021-12-27</td>\n      <td>2.7</td>\n      <td>0.4</td>\n      <td>-4.5</td>\n      <td>59.6</td>\n      <td>1.68</td>\n      <td>100</td>\n      <td>rain</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>25.90</td>\n      <td>17.2</td>\n      <td>116.3</td>\n      <td>1016.8</td>\n      <td>65.8</td>\n      <td>15.5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>361</th>\n      <td>2021-12-28</td>\n      <td>5.9</td>\n      <td>4.3</td>\n      <td>0.8</td>\n      <td>71.6</td>\n      <td>0.53</td>\n      <td>100</td>\n      <td>rain</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>22.00</td>\n      <td>16.9</td>\n      <td>216.0</td>\n      <td>1010.6</td>\n      <td>76.4</td>\n      <td>13.7</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>362</th>\n      <td>2021-12-29</td>\n      <td>5.9</td>\n      <td>3.8</td>\n      <td>3.9</td>\n      <td>87.0</td>\n      <td>5.50</td>\n      <td>100</td>\n      <td>rain</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>25.90</td>\n      <td>19.9</td>\n      <td>52.0</td>\n      <td>1012.3</td>\n      <td>100.0</td>\n      <td>8.8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>363</th>\n      <td>2021-12-30</td>\n      <td>7.8</td>\n      <td>7.0</td>\n      <td>5.8</td>\n      <td>87.1</td>\n      <td>1.52</td>\n      <td>100</td>\n      <td>rain</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>25.90</td>\n      <td>9.1</td>\n      <td>67.2</td>\n      <td>1013.7</td>\n      <td>98.8</td>\n      <td>8.4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>364</th>\n      <td>2021-12-31</td>\n      <td>10.3</td>\n      <td>10.2</td>\n      <td>7.8</td>\n      <td>84.3</td>\n      <td>0.05</td>\n      <td>100</td>\n      <td>rain</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.20</td>\n      <td>12.0</td>\n      <td>223.0</td>\n      <td>1013.7</td>\n      <td>96.1</td>\n      <td>11.1</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>365 rows × 17 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-04-10T04:42:09.906995Z","iopub.execute_input":"2024-04-10T04:42:09.907339Z","iopub.status.idle":"2024-04-10T04:42:09.915749Z","shell.execute_reply.started":"2024-04-10T04:42:09.907306Z","shell.execute_reply":"2024-04-10T04:42:09.914591Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"datetime            0\ntemp                0\nfeelslike           0\ndew                 0\nhumidity            0\nprecip              0\nprecipprob          0\npreciptype          0\nsnow                0\nsnowdepth           0\nwindgust            0\nwindspeed           0\nwinddir             0\nsealevelpressure    0\ncloudcover          0\nvisibility          0\nuvindex             0\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"Weather Data Cleaned And Transformed\n","metadata":{}},{"cell_type":"code","source":"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pyarrow.parquet as pq\ntd1 = pd.read_parquet('/kaggle/input/uber-nyc-forhire-vehicles-trip-data-2021/fhvhv_tripdata_2021-01.parquet')","metadata":{"execution":{"iopub.status.busy":"2024-04-10T04:42:09.916860Z","iopub.execute_input":"2024-04-10T04:42:09.917163Z","iopub.status.idle":"2024-04-10T04:42:19.389115Z","shell.execute_reply.started":"2024-04-10T04:42:09.917132Z","shell.execute_reply":"2024-04-10T04:42:19.388299Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"td1.head(4)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T04:42:19.390153Z","iopub.execute_input":"2024-04-10T04:42:19.390403Z","iopub.status.idle":"2024-04-10T04:42:19.416307Z","shell.execute_reply.started":"2024-04-10T04:42:19.390381Z","shell.execute_reply":"2024-04-10T04:42:19.415301Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"  hvfhs_license_num dispatching_base_num originating_base_num  \\\n0            HV0003               B02682               B02682   \n1            HV0003               B02682               B02682   \n2            HV0003               B02764               B02764   \n3            HV0003               B02764               B02764   \n\n     request_datetime   on_scene_datetime     pickup_datetime  \\\n0 2021-01-01 00:28:09 2021-01-01 00:31:42 2021-01-01 00:33:44   \n1 2021-01-01 00:45:56 2021-01-01 00:55:19 2021-01-01 00:55:19   \n2 2021-01-01 00:21:15 2021-01-01 00:22:41 2021-01-01 00:23:56   \n3 2021-01-01 00:39:12 2021-01-01 00:42:37 2021-01-01 00:42:51   \n\n     dropoff_datetime  PULocationID  DOLocationID  trip_miles  ...  sales_tax  \\\n0 2021-01-01 00:49:07           230           166        5.26  ...       1.98   \n1 2021-01-01 01:18:21           152           167        3.65  ...       1.63   \n2 2021-01-01 00:38:05           233           142        3.51  ...       1.25   \n3 2021-01-01 00:45:50           142           143        0.74  ...       0.70   \n\n   congestion_surcharge  airport_fee  tips  driver_pay  shared_request_flag  \\\n0                  2.75          NaN  0.00       14.99                    N   \n1                  0.00          NaN  0.00       17.06                    N   \n2                  2.75          NaN  0.94       12.98                    N   \n3                  2.75          NaN  0.00        7.41                    N   \n\n   shared_match_flag  access_a_ride_flag  wav_request_flag wav_match_flag  \n0                  N                                     N              N  \n1                  N                                     N              N  \n2                  N                                     N              N  \n3                  N                                     N              N  \n\n[4 rows x 24 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hvfhs_license_num</th>\n      <th>dispatching_base_num</th>\n      <th>originating_base_num</th>\n      <th>request_datetime</th>\n      <th>on_scene_datetime</th>\n      <th>pickup_datetime</th>\n      <th>dropoff_datetime</th>\n      <th>PULocationID</th>\n      <th>DOLocationID</th>\n      <th>trip_miles</th>\n      <th>...</th>\n      <th>sales_tax</th>\n      <th>congestion_surcharge</th>\n      <th>airport_fee</th>\n      <th>tips</th>\n      <th>driver_pay</th>\n      <th>shared_request_flag</th>\n      <th>shared_match_flag</th>\n      <th>access_a_ride_flag</th>\n      <th>wav_request_flag</th>\n      <th>wav_match_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HV0003</td>\n      <td>B02682</td>\n      <td>B02682</td>\n      <td>2021-01-01 00:28:09</td>\n      <td>2021-01-01 00:31:42</td>\n      <td>2021-01-01 00:33:44</td>\n      <td>2021-01-01 00:49:07</td>\n      <td>230</td>\n      <td>166</td>\n      <td>5.26</td>\n      <td>...</td>\n      <td>1.98</td>\n      <td>2.75</td>\n      <td>NaN</td>\n      <td>0.00</td>\n      <td>14.99</td>\n      <td>N</td>\n      <td>N</td>\n      <td></td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HV0003</td>\n      <td>B02682</td>\n      <td>B02682</td>\n      <td>2021-01-01 00:45:56</td>\n      <td>2021-01-01 00:55:19</td>\n      <td>2021-01-01 00:55:19</td>\n      <td>2021-01-01 01:18:21</td>\n      <td>152</td>\n      <td>167</td>\n      <td>3.65</td>\n      <td>...</td>\n      <td>1.63</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>0.00</td>\n      <td>17.06</td>\n      <td>N</td>\n      <td>N</td>\n      <td></td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HV0003</td>\n      <td>B02764</td>\n      <td>B02764</td>\n      <td>2021-01-01 00:21:15</td>\n      <td>2021-01-01 00:22:41</td>\n      <td>2021-01-01 00:23:56</td>\n      <td>2021-01-01 00:38:05</td>\n      <td>233</td>\n      <td>142</td>\n      <td>3.51</td>\n      <td>...</td>\n      <td>1.25</td>\n      <td>2.75</td>\n      <td>NaN</td>\n      <td>0.94</td>\n      <td>12.98</td>\n      <td>N</td>\n      <td>N</td>\n      <td></td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HV0003</td>\n      <td>B02764</td>\n      <td>B02764</td>\n      <td>2021-01-01 00:39:12</td>\n      <td>2021-01-01 00:42:37</td>\n      <td>2021-01-01 00:42:51</td>\n      <td>2021-01-01 00:45:50</td>\n      <td>142</td>\n      <td>143</td>\n      <td>0.74</td>\n      <td>...</td>\n      <td>0.70</td>\n      <td>2.75</td>\n      <td>NaN</td>\n      <td>0.00</td>\n      <td>7.41</td>\n      <td>N</td>\n      <td>N</td>\n      <td></td>\n      <td>N</td>\n      <td>N</td>\n    </tr>\n  </tbody>\n</table>\n<p>4 rows × 24 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"td1['driver_pay_per_mile'] = td1['driver_pay'] / td1['trip_miles']\ntd1['trip_duration'] = (td1['dropoff_datetime'] - td1['pickup_datetime']).dt.total_seconds()/60\ntd1['driver_pay_per_minute'] = td1['driver_pay'] / td1['trip_duration']\n\nprint(td1.head())","metadata":{"execution":{"iopub.status.busy":"2024-04-10T04:42:19.417581Z","iopub.execute_input":"2024-04-10T04:42:19.417977Z","iopub.status.idle":"2024-04-10T04:42:19.864404Z","shell.execute_reply.started":"2024-04-10T04:42:19.417951Z","shell.execute_reply":"2024-04-10T04:42:19.863392Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"  hvfhs_license_num dispatching_base_num originating_base_num  \\\n0            HV0003               B02682               B02682   \n1            HV0003               B02682               B02682   \n2            HV0003               B02764               B02764   \n3            HV0003               B02764               B02764   \n4            HV0003               B02764               B02764   \n\n     request_datetime   on_scene_datetime     pickup_datetime  \\\n0 2021-01-01 00:28:09 2021-01-01 00:31:42 2021-01-01 00:33:44   \n1 2021-01-01 00:45:56 2021-01-01 00:55:19 2021-01-01 00:55:19   \n2 2021-01-01 00:21:15 2021-01-01 00:22:41 2021-01-01 00:23:56   \n3 2021-01-01 00:39:12 2021-01-01 00:42:37 2021-01-01 00:42:51   \n4 2021-01-01 00:46:11 2021-01-01 00:47:17 2021-01-01 00:48:14   \n\n     dropoff_datetime  PULocationID  DOLocationID  trip_miles  ...  tips  \\\n0 2021-01-01 00:49:07           230           166        5.26  ...  0.00   \n1 2021-01-01 01:18:21           152           167        3.65  ...  0.00   \n2 2021-01-01 00:38:05           233           142        3.51  ...  0.94   \n3 2021-01-01 00:45:50           142           143        0.74  ...  0.00   \n4 2021-01-01 01:08:42           143            78        9.20  ...  0.00   \n\n   driver_pay  shared_request_flag  shared_match_flag  access_a_ride_flag  \\\n0       14.99                    N                  N                       \n1       17.06                    N                  N                       \n2       12.98                    N                  N                       \n3        7.41                    N                  N                       \n4       22.44                    N                  N                       \n\n   wav_request_flag  wav_match_flag  driver_pay_per_mile  trip_duration  \\\n0                 N               N             2.849810      15.383333   \n1                 N               N             4.673973      23.033333   \n2                 N               N             3.698006      14.150000   \n3                 N               N            10.013514       2.983333   \n4                 N               N             2.439130      20.466667   \n\n  driver_pay_per_minute  \n0              0.974431  \n1              0.740666  \n2              0.917314  \n3              2.483799  \n4              1.096417  \n\n[5 rows x 27 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-04-10T05:14:54.582089Z","iopub.execute_input":"2024-04-10T05:14:54.582847Z","iopub.status.idle":"2024-04-10T05:14:54.616548Z","shell.execute_reply.started":"2024-04-10T05:14:54.582815Z","shell.execute_reply":"2024-04-10T05:14:54.615607Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"       datetime  temp  feelslike  dew  humidity  precip  precipprob  \\\n0    2021-01-01   2.5       -0.2 -3.0      67.8   15.33         100   \n1    2021-01-02   5.8        3.6  1.2      74.0    2.38         100   \n2    2021-01-03   2.5       -1.6 -0.5      80.7    5.09         100   \n3    2021-01-04   3.6        1.1 -0.2      76.6    0.84         100   \n4    2021-01-05   3.8        1.3 -1.5      68.7    0.00           0   \n..          ...   ...        ...  ...       ...     ...         ...   \n360  2021-12-27   2.7        0.4 -4.5      59.6    1.68         100   \n361  2021-12-28   5.9        4.3  0.8      71.6    0.53         100   \n362  2021-12-29   5.9        3.8  3.9      87.0    5.50         100   \n363  2021-12-30   7.8        7.0  5.8      87.1    1.52         100   \n364  2021-12-31  10.3       10.2  7.8      84.3    0.05         100   \n\n    preciptype  snow  snowdepth  windgust  windspeed  winddir  \\\n0         rain   0.0        0.0     33.19       15.5     69.8   \n1         rain   1.9        0.6     54.60       25.5    246.9   \n2    rain,snow   1.2        1.7     42.20       24.1     66.4   \n3    rain,snow   0.5        0.7     36.08       17.3    141.1   \n4        clear   0.0        0.1     31.70       15.2    124.4   \n..         ...   ...        ...       ...        ...      ...   \n360       rain   0.0        0.0     25.90       17.2    116.3   \n361       rain   0.0        0.0     22.00       16.9    216.0   \n362       rain   0.0        0.0     25.90       19.9     52.0   \n363       rain   0.0        0.0     25.90        9.1     67.2   \n364       rain   0.0        0.0     40.20       12.0    223.0   \n\n     sealevelpressure  cloudcover  visibility  uvindex  \n0              1028.9        50.6        14.0        3  \n1              1012.4        63.9        12.2        5  \n2              1017.0        81.5        13.2        1  \n3              1014.6        89.3        15.6        4  \n4              1013.1        98.8        16.0        2  \n..                ...         ...         ...      ...  \n360            1016.8        65.8        15.5        2  \n361            1010.6        76.4        13.7        2  \n362            1012.3       100.0         8.8        1  \n363            1013.7        98.8         8.4        2  \n364            1013.7        96.1        11.1        3  \n\n[365 rows x 17 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>datetime</th>\n      <th>temp</th>\n      <th>feelslike</th>\n      <th>dew</th>\n      <th>humidity</th>\n      <th>precip</th>\n      <th>precipprob</th>\n      <th>preciptype</th>\n      <th>snow</th>\n      <th>snowdepth</th>\n      <th>windgust</th>\n      <th>windspeed</th>\n      <th>winddir</th>\n      <th>sealevelpressure</th>\n      <th>cloudcover</th>\n      <th>visibility</th>\n      <th>uvindex</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-01-01</td>\n      <td>2.5</td>\n      <td>-0.2</td>\n      <td>-3.0</td>\n      <td>67.8</td>\n      <td>15.33</td>\n      <td>100</td>\n      <td>rain</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>33.19</td>\n      <td>15.5</td>\n      <td>69.8</td>\n      <td>1028.9</td>\n      <td>50.6</td>\n      <td>14.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-01-02</td>\n      <td>5.8</td>\n      <td>3.6</td>\n      <td>1.2</td>\n      <td>74.0</td>\n      <td>2.38</td>\n      <td>100</td>\n      <td>rain</td>\n      <td>1.9</td>\n      <td>0.6</td>\n      <td>54.60</td>\n      <td>25.5</td>\n      <td>246.9</td>\n      <td>1012.4</td>\n      <td>63.9</td>\n      <td>12.2</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-01-03</td>\n      <td>2.5</td>\n      <td>-1.6</td>\n      <td>-0.5</td>\n      <td>80.7</td>\n      <td>5.09</td>\n      <td>100</td>\n      <td>rain,snow</td>\n      <td>1.2</td>\n      <td>1.7</td>\n      <td>42.20</td>\n      <td>24.1</td>\n      <td>66.4</td>\n      <td>1017.0</td>\n      <td>81.5</td>\n      <td>13.2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-01-04</td>\n      <td>3.6</td>\n      <td>1.1</td>\n      <td>-0.2</td>\n      <td>76.6</td>\n      <td>0.84</td>\n      <td>100</td>\n      <td>rain,snow</td>\n      <td>0.5</td>\n      <td>0.7</td>\n      <td>36.08</td>\n      <td>17.3</td>\n      <td>141.1</td>\n      <td>1014.6</td>\n      <td>89.3</td>\n      <td>15.6</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-01-05</td>\n      <td>3.8</td>\n      <td>1.3</td>\n      <td>-1.5</td>\n      <td>68.7</td>\n      <td>0.00</td>\n      <td>0</td>\n      <td>clear</td>\n      <td>0.0</td>\n      <td>0.1</td>\n      <td>31.70</td>\n      <td>15.2</td>\n      <td>124.4</td>\n      <td>1013.1</td>\n      <td>98.8</td>\n      <td>16.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>360</th>\n      <td>2021-12-27</td>\n      <td>2.7</td>\n      <td>0.4</td>\n      <td>-4.5</td>\n      <td>59.6</td>\n      <td>1.68</td>\n      <td>100</td>\n      <td>rain</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>25.90</td>\n      <td>17.2</td>\n      <td>116.3</td>\n      <td>1016.8</td>\n      <td>65.8</td>\n      <td>15.5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>361</th>\n      <td>2021-12-28</td>\n      <td>5.9</td>\n      <td>4.3</td>\n      <td>0.8</td>\n      <td>71.6</td>\n      <td>0.53</td>\n      <td>100</td>\n      <td>rain</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>22.00</td>\n      <td>16.9</td>\n      <td>216.0</td>\n      <td>1010.6</td>\n      <td>76.4</td>\n      <td>13.7</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>362</th>\n      <td>2021-12-29</td>\n      <td>5.9</td>\n      <td>3.8</td>\n      <td>3.9</td>\n      <td>87.0</td>\n      <td>5.50</td>\n      <td>100</td>\n      <td>rain</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>25.90</td>\n      <td>19.9</td>\n      <td>52.0</td>\n      <td>1012.3</td>\n      <td>100.0</td>\n      <td>8.8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>363</th>\n      <td>2021-12-30</td>\n      <td>7.8</td>\n      <td>7.0</td>\n      <td>5.8</td>\n      <td>87.1</td>\n      <td>1.52</td>\n      <td>100</td>\n      <td>rain</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>25.90</td>\n      <td>9.1</td>\n      <td>67.2</td>\n      <td>1013.7</td>\n      <td>98.8</td>\n      <td>8.4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>364</th>\n      <td>2021-12-31</td>\n      <td>10.3</td>\n      <td>10.2</td>\n      <td>7.8</td>\n      <td>84.3</td>\n      <td>0.05</td>\n      <td>100</td>\n      <td>rain</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.20</td>\n      <td>12.0</td>\n      <td>223.0</td>\n      <td>1013.7</td>\n      <td>96.1</td>\n      <td>11.1</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>365 rows × 17 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"td1['date'] = pd.to_datetime(td1['request_datetime']).dt.strftime('%Y-%m-%d')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-10T05:13:41.882091Z","iopub.execute_input":"2024-04-10T05:13:41.882815Z","iopub.status.idle":"2024-04-10T05:14:05.674957Z","shell.execute_reply.started":"2024-04-10T05:13:41.882782Z","shell.execute_reply":"2024-04-10T05:14:05.673903Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"         hvfhs_license_num dispatching_base_num originating_base_num  \\\n0                   HV0003               B02682               B02682   \n1                   HV0003               B02682               B02682   \n2                   HV0003               B02764               B02764   \n3                   HV0003               B02764               B02764   \n4                   HV0003               B02764               B02764   \n...                    ...                  ...                  ...   \n11908463            HV0003               B02765               B02765   \n11908464            HV0003               B02872               B02872   \n11908465            HV0003               B02872               B02872   \n11908466            HV0003               B02764               B02764   \n11908467            HV0003               B02764               B02764   \n\n            request_datetime   on_scene_datetime     pickup_datetime  \\\n0        2021-01-01 00:28:09 2021-01-01 00:31:42 2021-01-01 00:33:44   \n1        2021-01-01 00:45:56 2021-01-01 00:55:19 2021-01-01 00:55:19   \n2        2021-01-01 00:21:15 2021-01-01 00:22:41 2021-01-01 00:23:56   \n3        2021-01-01 00:39:12 2021-01-01 00:42:37 2021-01-01 00:42:51   \n4        2021-01-01 00:46:11 2021-01-01 00:47:17 2021-01-01 00:48:14   \n...                      ...                 ...                 ...   \n11908463 2021-01-31 23:13:51 2021-01-31 23:25:03 2021-01-31 23:25:40   \n11908464 2021-01-31 23:23:56 2021-01-31 23:29:03 2021-01-31 23:29:31   \n11908465 2021-01-31 23:42:53 2021-01-31 23:49:23 2021-01-31 23:49:32   \n11908466 2021-01-31 23:04:32 2021-01-31 23:09:13 2021-01-31 23:09:29   \n11908467 2021-01-31 23:22:20 2021-01-31 23:28:33 2021-01-31 23:28:33   \n\n            dropoff_datetime  PULocationID  DOLocationID  trip_miles  ...  \\\n0        2021-01-01 00:49:07           230           166        5.26  ...   \n1        2021-01-01 01:18:21           152           167        3.65  ...   \n2        2021-01-01 00:38:05           233           142        3.51  ...   \n3        2021-01-01 00:45:50           142           143        0.74  ...   \n4        2021-01-01 01:08:42           143            78        9.20  ...   \n...                      ...           ...           ...         ...  ...   \n11908463 2021-01-31 23:40:10            89            71        2.29  ...   \n11908464 2021-01-31 23:47:44           182           167        4.10  ...   \n11908465 2021-02-01 00:04:36           167           169        2.40  ...   \n11908466 2021-01-31 23:27:46           188            37        3.60  ...   \n11908467 2021-01-31 23:56:36            37             4        5.76  ...   \n\n          driver_pay  shared_request_flag  shared_match_flag  \\\n0              14.99                    N                  N   \n1              17.06                    N                  N   \n2              12.98                    N                  N   \n3               7.41                    N                  N   \n4              22.44                    N                  N   \n...              ...                  ...                ...   \n11908463       12.06                    N                  N   \n11908464       13.66                    N                  N   \n11908465       15.53                    N                  N   \n11908466       17.36                    N                  N   \n11908467       21.69                    N                  N   \n\n          access_a_ride_flag  wav_request_flag  wav_match_flag  \\\n0                                            N               N   \n1                                            N               N   \n2                                            N               N   \n3                                            N               N   \n4                                            N               N   \n...                      ...               ...             ...   \n11908463                                     N               N   \n11908464                                     N               N   \n11908465                                     N               N   \n11908466                                     N               N   \n11908467                                     N               N   \n\n          driver_pay_per_mile  trip_duration  driver_pay_per_minute  \\\n0                    2.849810      15.383333               0.974431   \n1                    4.673973      23.033333               0.740666   \n2                    3.698006      14.150000               0.917314   \n3                   10.013514       2.983333               2.483799   \n4                    2.439130      20.466667               1.096417   \n...                       ...            ...                    ...   \n11908463             5.266376      14.500000               0.831724   \n11908464             3.331707      18.216667               0.749863   \n11908465             6.470833      15.066667               1.030752   \n11908466             4.822222      18.283333               0.949499   \n11908467             3.765625      28.050000               0.773262   \n\n                date  \n0         2021-01-01  \n1         2021-01-01  \n2         2021-01-01  \n3         2021-01-01  \n4         2021-01-01  \n...              ...  \n11908463  2021-01-31  \n11908464  2021-01-31  \n11908465  2021-01-31  \n11908466  2021-01-31  \n11908467  2021-01-31  \n\n[11908468 rows x 28 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hvfhs_license_num</th>\n      <th>dispatching_base_num</th>\n      <th>originating_base_num</th>\n      <th>request_datetime</th>\n      <th>on_scene_datetime</th>\n      <th>pickup_datetime</th>\n      <th>dropoff_datetime</th>\n      <th>PULocationID</th>\n      <th>DOLocationID</th>\n      <th>trip_miles</th>\n      <th>...</th>\n      <th>driver_pay</th>\n      <th>shared_request_flag</th>\n      <th>shared_match_flag</th>\n      <th>access_a_ride_flag</th>\n      <th>wav_request_flag</th>\n      <th>wav_match_flag</th>\n      <th>driver_pay_per_mile</th>\n      <th>trip_duration</th>\n      <th>driver_pay_per_minute</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HV0003</td>\n      <td>B02682</td>\n      <td>B02682</td>\n      <td>2021-01-01 00:28:09</td>\n      <td>2021-01-01 00:31:42</td>\n      <td>2021-01-01 00:33:44</td>\n      <td>2021-01-01 00:49:07</td>\n      <td>230</td>\n      <td>166</td>\n      <td>5.26</td>\n      <td>...</td>\n      <td>14.99</td>\n      <td>N</td>\n      <td>N</td>\n      <td></td>\n      <td>N</td>\n      <td>N</td>\n      <td>2.849810</td>\n      <td>15.383333</td>\n      <td>0.974431</td>\n      <td>2021-01-01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HV0003</td>\n      <td>B02682</td>\n      <td>B02682</td>\n      <td>2021-01-01 00:45:56</td>\n      <td>2021-01-01 00:55:19</td>\n      <td>2021-01-01 00:55:19</td>\n      <td>2021-01-01 01:18:21</td>\n      <td>152</td>\n      <td>167</td>\n      <td>3.65</td>\n      <td>...</td>\n      <td>17.06</td>\n      <td>N</td>\n      <td>N</td>\n      <td></td>\n      <td>N</td>\n      <td>N</td>\n      <td>4.673973</td>\n      <td>23.033333</td>\n      <td>0.740666</td>\n      <td>2021-01-01</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HV0003</td>\n      <td>B02764</td>\n      <td>B02764</td>\n      <td>2021-01-01 00:21:15</td>\n      <td>2021-01-01 00:22:41</td>\n      <td>2021-01-01 00:23:56</td>\n      <td>2021-01-01 00:38:05</td>\n      <td>233</td>\n      <td>142</td>\n      <td>3.51</td>\n      <td>...</td>\n      <td>12.98</td>\n      <td>N</td>\n      <td>N</td>\n      <td></td>\n      <td>N</td>\n      <td>N</td>\n      <td>3.698006</td>\n      <td>14.150000</td>\n      <td>0.917314</td>\n      <td>2021-01-01</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HV0003</td>\n      <td>B02764</td>\n      <td>B02764</td>\n      <td>2021-01-01 00:39:12</td>\n      <td>2021-01-01 00:42:37</td>\n      <td>2021-01-01 00:42:51</td>\n      <td>2021-01-01 00:45:50</td>\n      <td>142</td>\n      <td>143</td>\n      <td>0.74</td>\n      <td>...</td>\n      <td>7.41</td>\n      <td>N</td>\n      <td>N</td>\n      <td></td>\n      <td>N</td>\n      <td>N</td>\n      <td>10.013514</td>\n      <td>2.983333</td>\n      <td>2.483799</td>\n      <td>2021-01-01</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HV0003</td>\n      <td>B02764</td>\n      <td>B02764</td>\n      <td>2021-01-01 00:46:11</td>\n      <td>2021-01-01 00:47:17</td>\n      <td>2021-01-01 00:48:14</td>\n      <td>2021-01-01 01:08:42</td>\n      <td>143</td>\n      <td>78</td>\n      <td>9.20</td>\n      <td>...</td>\n      <td>22.44</td>\n      <td>N</td>\n      <td>N</td>\n      <td></td>\n      <td>N</td>\n      <td>N</td>\n      <td>2.439130</td>\n      <td>20.466667</td>\n      <td>1.096417</td>\n      <td>2021-01-01</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11908463</th>\n      <td>HV0003</td>\n      <td>B02765</td>\n      <td>B02765</td>\n      <td>2021-01-31 23:13:51</td>\n      <td>2021-01-31 23:25:03</td>\n      <td>2021-01-31 23:25:40</td>\n      <td>2021-01-31 23:40:10</td>\n      <td>89</td>\n      <td>71</td>\n      <td>2.29</td>\n      <td>...</td>\n      <td>12.06</td>\n      <td>N</td>\n      <td>N</td>\n      <td></td>\n      <td>N</td>\n      <td>N</td>\n      <td>5.266376</td>\n      <td>14.500000</td>\n      <td>0.831724</td>\n      <td>2021-01-31</td>\n    </tr>\n    <tr>\n      <th>11908464</th>\n      <td>HV0003</td>\n      <td>B02872</td>\n      <td>B02872</td>\n      <td>2021-01-31 23:23:56</td>\n      <td>2021-01-31 23:29:03</td>\n      <td>2021-01-31 23:29:31</td>\n      <td>2021-01-31 23:47:44</td>\n      <td>182</td>\n      <td>167</td>\n      <td>4.10</td>\n      <td>...</td>\n      <td>13.66</td>\n      <td>N</td>\n      <td>N</td>\n      <td></td>\n      <td>N</td>\n      <td>N</td>\n      <td>3.331707</td>\n      <td>18.216667</td>\n      <td>0.749863</td>\n      <td>2021-01-31</td>\n    </tr>\n    <tr>\n      <th>11908465</th>\n      <td>HV0003</td>\n      <td>B02872</td>\n      <td>B02872</td>\n      <td>2021-01-31 23:42:53</td>\n      <td>2021-01-31 23:49:23</td>\n      <td>2021-01-31 23:49:32</td>\n      <td>2021-02-01 00:04:36</td>\n      <td>167</td>\n      <td>169</td>\n      <td>2.40</td>\n      <td>...</td>\n      <td>15.53</td>\n      <td>N</td>\n      <td>N</td>\n      <td></td>\n      <td>N</td>\n      <td>N</td>\n      <td>6.470833</td>\n      <td>15.066667</td>\n      <td>1.030752</td>\n      <td>2021-01-31</td>\n    </tr>\n    <tr>\n      <th>11908466</th>\n      <td>HV0003</td>\n      <td>B02764</td>\n      <td>B02764</td>\n      <td>2021-01-31 23:04:32</td>\n      <td>2021-01-31 23:09:13</td>\n      <td>2021-01-31 23:09:29</td>\n      <td>2021-01-31 23:27:46</td>\n      <td>188</td>\n      <td>37</td>\n      <td>3.60</td>\n      <td>...</td>\n      <td>17.36</td>\n      <td>N</td>\n      <td>N</td>\n      <td></td>\n      <td>N</td>\n      <td>N</td>\n      <td>4.822222</td>\n      <td>18.283333</td>\n      <td>0.949499</td>\n      <td>2021-01-31</td>\n    </tr>\n    <tr>\n      <th>11908467</th>\n      <td>HV0003</td>\n      <td>B02764</td>\n      <td>B02764</td>\n      <td>2021-01-31 23:22:20</td>\n      <td>2021-01-31 23:28:33</td>\n      <td>2021-01-31 23:28:33</td>\n      <td>2021-01-31 23:56:36</td>\n      <td>37</td>\n      <td>4</td>\n      <td>5.76</td>\n      <td>...</td>\n      <td>21.69</td>\n      <td>N</td>\n      <td>N</td>\n      <td></td>\n      <td>N</td>\n      <td>N</td>\n      <td>3.765625</td>\n      <td>28.050000</td>\n      <td>0.773262</td>\n      <td>2021-01-31</td>\n    </tr>\n  </tbody>\n</table>\n<p>11908468 rows × 28 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"td1.dropna(subset=['date'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T05:22:42.083505Z","iopub.execute_input":"2024-04-10T05:22:42.084379Z","iopub.status.idle":"2024-04-10T05:22:46.394162Z","shell.execute_reply.started":"2024-04-10T05:22:42.084347Z","shell.execute_reply":"2024-04-10T05:22:46.393353Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"td1.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-04-10T05:22:47.178092Z","iopub.execute_input":"2024-04-10T05:22:47.178743Z","iopub.status.idle":"2024-04-10T05:22:57.268507Z","shell.execute_reply.started":"2024-04-10T05:22:47.178708Z","shell.execute_reply":"2024-04-10T05:22:57.267487Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"hvfhs_license_num               0\ndispatching_base_num            0\noriginating_base_num      3206075\nrequest_datetime                0\non_scene_datetime         3200011\npickup_datetime                 0\ndropoff_datetime                0\nPULocationID                    0\nDOLocationID                    0\ntrip_miles                      0\ntrip_time                       0\nbase_passenger_fare             0\ntolls                           0\nbcf                             0\nsales_tax                       0\ncongestion_surcharge            0\nairport_fee              11902544\ntips                            0\ndriver_pay                      0\nshared_request_flag             0\nshared_match_flag               0\naccess_a_ride_flag              0\nwav_request_flag                0\nwav_match_flag                  0\ndriver_pay_per_mile           943\ntrip_duration                   0\ndriver_pay_per_minute          53\ndate                            0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nfrom gensim.models import Word2Vec\n\n# Tokenize the dates\ntokenized_dates = [date.split('-') for date in td1['date']]\n\n# Train Word2Vec model\nword2vec_model = Word2Vec(sentences=tokenized_dates, vector_size=10, window=5, min_count=1, workers=4)\n\n# Get embedding vectors for each date\ndate_embeddings = [word2vec_model.wv[date] for date in tokenized_dates]\n\n# Convert to DataFrame\ndate_embeddings_df = pd.DataFrame(date_embeddings, columns=[f'date_embedding_{i}' for i in range(15000)])  # Adjust the number of columns based on vector_size\n\n# Concatenate with the original DataFrame\ntd1 = pd.concat([td1, date_embeddings_df], axis=1)\n\n# Drop the original 'date' column\ntd1.drop('date', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T05:23:02.962201Z","iopub.execute_input":"2024-04-10T05:23:02.962854Z","iopub.status.idle":"2024-04-10T05:29:18.530869Z","shell.execute_reply.started":"2024-04-10T05:23:02.962820Z","shell.execute_reply":"2024-04-10T05:29:18.529637Z"},"trusted":true},"execution_count":44,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[44], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m date_embeddings \u001b[38;5;241m=\u001b[39m [word2vec_model\u001b[38;5;241m.\u001b[39mwv[date] \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m tokenized_dates]\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Convert to DataFrame\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m date_embeddings_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate_embedding_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m15000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust the number of columns based on vector_size\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Concatenate with the original DataFrame\u001b[39;00m\n\u001b[1;32m     20\u001b[0m td1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([td1, date_embeddings_df], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:856\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    848\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    849\u001b[0m             arrays,\n\u001b[1;32m    850\u001b[0m             columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    853\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    854\u001b[0m         )\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    865\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    866\u001b[0m         {},\n\u001b[1;32m    867\u001b[0m         index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    870\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    871\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:319\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    314\u001b[0m     values \u001b[38;5;241m=\u001b[39m _ensure_2d(values)\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# by definition an array here\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;66;03m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_prep_ndarraylike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy_on_sanitize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;66;03m# GH#40110 see similar check inside sanitize_array\u001b[39;00m\n\u001b[1;32m    323\u001b[0m     values \u001b[38;5;241m=\u001b[39m sanitize_array(\n\u001b[1;32m    324\u001b[0m         values,\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    328\u001b[0m         allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:582\u001b[0m, in \u001b[0;36m_prep_ndarraylike\u001b[0;34m(values, copy)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    580\u001b[0m     values \u001b[38;5;241m=\u001b[39m convert(values)\n\u001b[0;32m--> 582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ensure_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:592\u001b[0m, in \u001b[0;36m_ensure_2d\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    590\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mreshape((values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust pass 2-d input. shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n","\u001b[0;31mValueError\u001b[0m: Must pass 2-d input. shape=(11908464, 3, 10)"],"ename":"ValueError","evalue":"Must pass 2-d input. shape=(11908464, 3, 10)","output_type":"error"}]},{"cell_type":"markdown","source":"# Model 1","metadata":{}},{"cell_type":"code","source":"!pip install tensorflow keras\n!pip install --upgrade pip\nimport tensorflow as tf\nfrom tensorflow import keras","metadata":{"execution":{"iopub.status.busy":"2024-04-10T04:42:24.614010Z","iopub.execute_input":"2024-04-10T04:42:24.614364Z","iopub.status.idle":"2024-04-10T04:43:15.217127Z","shell.execute_reply.started":"2024-04-10T04:42:24.614337Z","shell.execute_reply":"2024-04-10T04:43:15.216071Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (3.1.1)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.51.1)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nCollecting keras\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\nDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 3.1.1\n    Uninstalling keras-3.1.1:\n      Successfully uninstalled keras-3.1.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0\nRequirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.3.2)\nCollecting pip\n  Downloading pip-24.0-py3-none-any.whl.metadata (3.6 kB)\nDownloading pip-24.0-py3-none-any.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 23.3.2\n    Uninstalling pip-23.3.2:\n      Successfully uninstalled pip-23.3.2\nSuccessfully installed pip-24.0\n","output_type":"stream"},{"name":"stderr","text":"2024-04-10 04:43:05.468532: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-10 04:43:05.468675: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-10 04:43:05.607553: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# create a neural network model for predicting driver pay per mile based on all trip td1. Create a model with 3 hidden layers, each with 64 nodes and ReLU activation functions. Use the Adam optimizer and mean squared error loss function. Train the model for 10 epochs.\n\nmodel = keras.Sequential([\n    keras.layers.Flatten(input_shape=(3,)),\n    keras.layers.Dense(64, activation='relu'),\n    keras.layers.Dense(32, activation='relu'),\n    keras.layers.Dense(1, activation='linear')\n])\n\n# training td1\n# training_td1 = td1[1:td1.shape[0]//2]\n# target_td1 = td1[td1.shape[0]//2:]\ntraining_td1 = td1.iloc[:12000]  #\ntarget_td1 = td1.iloc[12000:15000]\n\nmodel.compile(optimizer='adam', loss='mean_squared_error')\nmodel.fit(training_td1[['trip_miles', 'trip_duration','date']], training_td1['driver_pay'], epochs=5)\n\n# Use the model to predict driver pay per mile for the first 5 trips in the td1set. Compare the predicted values to the actual values.\npredictions = model.predict(target_td1[['trip_miles', 'trip_duration','date']] )\nprint(predictions[:5])\nprint(target_td1['driver_pay'][:5])","metadata":{"execution":{"iopub.status.busy":"2024-04-10T05:15:48.569754Z","iopub.execute_input":"2024-04-10T05:15:48.570129Z","iopub.status.idle":"2024-04-10T05:15:48.748473Z","shell.execute_reply.started":"2024-04-10T05:15:48.570102Z","shell.execute_reply":"2024-04-10T05:15:48.747295Z"},"trusted":true},"execution_count":36,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[36], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m target_td1 \u001b[38;5;241m=\u001b[39m td1\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m12000\u001b[39m:\u001b[38;5;241m15000\u001b[39m]\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_td1\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrip_miles\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrip_duration\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_td1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdriver_pay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Use the model to predict driver pay per mile for the first 5 trips in the td1set. Compare the predicted values to the actual values.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(target_td1[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrip_miles\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrip_duration\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]] )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    102\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."],"ename":"ValueError","evalue":"Failed to convert a NumPy array to a Tensor (Unsupported object type float).","output_type":"error"}]},{"cell_type":"code","source":"print(model.evaluate(target_td1[['trip_miles', 'trip_duration']], target_td1['driver_pay']))\nmodel.save('m1.keras')","metadata":{"execution":{"iopub.status.busy":"2024-04-10T04:58:38.654554Z","iopub.execute_input":"2024-04-10T04:58:38.655355Z","iopub.status.idle":"2024-04-10T04:58:39.055772Z","shell.execute_reply.started":"2024-04-10T04:58:38.655322Z","shell.execute_reply":"2024-04-10T04:58:39.054749Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"94/94 [==============================] - 0s 2ms/step - loss: 9.8533\n9.853256225585938\n","output_type":"stream"}]},{"cell_type":"code","source":"new_model = tf.keras.models.load_model('m1.keras')\n\nprint(new_model.predict(target_td1[1:50][['trip_miles', 'trip_duration']]))\nprint(target_td1[1:50]['driver_pay'])","metadata":{"execution":{"iopub.status.busy":"2024-04-10T05:00:01.219449Z","iopub.execute_input":"2024-04-10T05:00:01.220460Z","iopub.status.idle":"2024-04-10T05:00:01.450450Z","shell.execute_reply.started":"2024-04-10T05:00:01.220414Z","shell.execute_reply":"2024-04-10T05:00:01.449362Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"2/2 [==============================] - 0s 3ms/step\n[[ 7.823266 ]\n [11.951415 ]\n [ 6.551437 ]\n [11.183859 ]\n [10.520539 ]\n [ 6.854458 ]\n [11.501509 ]\n [21.929268 ]\n [15.498501 ]\n [15.498501 ]\n [13.4894285]\n [ 6.888594 ]\n [13.841204 ]\n [10.8228   ]\n [ 8.018373 ]\n [ 9.614493 ]\n [49.02986  ]\n [ 7.324812 ]\n [ 5.3594394]\n [ 5.839755 ]\n [11.869579 ]\n [10.96464  ]\n [10.459655 ]\n [15.596986 ]\n [11.502907 ]\n [18.222593 ]\n [33.02128  ]\n [ 7.760792 ]\n [ 5.142463 ]\n [10.1904   ]\n [ 5.3606925]\n [10.558526 ]\n [ 6.326422 ]\n [39.424114 ]\n [16.54639  ]\n [ 4.5475283]\n [11.349429 ]\n [12.274107 ]\n [ 6.9438586]\n [11.522159 ]\n [11.052291 ]\n [14.509304 ]\n [ 6.695664 ]\n [ 9.920801 ]\n [17.67815  ]\n [25.707834 ]\n [13.935371 ]\n [19.918018 ]\n [14.665782 ]]\n12001    13.63\n12002    18.51\n12003    13.67\n12004    17.64\n12005    10.63\n12006     6.97\n12007    11.65\n12008    21.79\n12009    16.96\n12010    16.96\n12011    14.67\n12012     8.41\n12013    15.08\n12014    11.75\n12015     8.61\n12016    10.82\n12017    47.99\n12018     7.37\n12019     7.59\n12020     7.38\n12021    13.62\n12022    12.63\n12023    10.19\n12024    14.77\n12025    10.82\n12026    24.27\n12027    29.95\n12028     5.70\n12029     7.18\n12030    10.53\n12031     7.65\n12032    10.69\n12033     7.15\n12034    37.57\n12035    15.45\n12036     6.30\n12037    11.63\n12038    12.68\n12039     6.93\n12040    30.29\n12041    15.33\n12042    20.04\n12043     7.77\n12044    10.97\n12045    18.17\n12046    23.72\n12047    13.50\n12048    19.72\n12049    13.50\nName: driver_pay, dtype: float64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model 2","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\n# train and test\ntraining_td1 = td1.iloc[:len(td1) // 2] \ntarget_td1 = td1.iloc[len(td1) // 2:]  \n\n# If 'td1' is a DataFrame, ensure to reset the index after splitting\ntraining_td1.reset_index(drop=True, inplace=True)\ntarget_td1.reset_index(drop=True, inplace=True)\n\n# Create and fit the linear regression model\nlinear_model = LinearRegression()\nlinear_model.fit(training_td1[['trip_miles', 'trip_duration']], training_td1['driver_pay'])\n\n# Use the model to predict driver pay per mile for the first 5 trips in the td1set.\npredictions_linear = linear_model.predict(target_td1[['trip_miles', 'trip_duration']])\nprint(predictions_linear[:5])\nprint(target_td1['driver_pay'][:5])","metadata":{"execution":{"iopub.status.busy":"2024-04-10T05:00:06.518029Z","iopub.execute_input":"2024-04-10T05:00:06.518404Z","iopub.status.idle":"2024-04-10T05:00:07.730471Z","shell.execute_reply.started":"2024-04-10T05:00:06.518372Z","shell.execute_reply":"2024-04-10T05:00:07.729059Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"[11.58908911  5.11332891 10.72302812  5.99919361  5.62534479]\n0    10.72\n1     5.40\n2     9.47\n3     5.40\n4     6.32\nName: driver_pay, dtype: float64\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\n# Calculate predictions using linear regression model\npredictions_linear = linear_model.predict(target_td1[['trip_miles', 'trip_duration']])\n\n# Calculate evaluation metrics\nmse_linear = mean_squared_error(target_td1['driver_pay'], predictions_linear)\nmae_linear = mean_absolute_error(target_td1['driver_pay'], predictions_linear)\nr2_linear = r2_score(target_td1['driver_pay'], predictions_linear)\n\n# Print evaluation metrics\nprint(\"Linear Regression Model Evaluation:\")\nprint(\"Mean Squared Error (MSE):\", mse_linear)\nprint(\"Mean Absolute Error (MAE):\", mae_linear)\nprint(\"R-squared (R2) Score:\", r2_linear)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T04:39:05.966845Z","iopub.execute_input":"2024-04-10T04:39:05.967549Z","iopub.status.idle":"2024-04-10T04:39:06.282603Z","shell.execute_reply.started":"2024-04-10T04:39:05.967519Z","shell.execute_reply":"2024-04-10T04:39:06.281716Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Linear Regression Model Evaluation:\nMean Squared Error (MSE): 10.107461814520493\nMean Absolute Error (MAE): 1.484554972969785\nR-squared (R2) Score: 0.9167569379811354\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model 3","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-04-10T05:00:48.899315Z","iopub.execute_input":"2024-04-10T05:00:48.899715Z","iopub.status.idle":"2024-04-10T05:00:48.906461Z","shell.execute_reply.started":"2024-04-10T05:00:48.899685Z","shell.execute_reply":"2024-04-10T05:00:48.905533Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Reshape the input data for LSTM\nn_features = 2  \nn_steps = 1   \n\n# # Reshape training and target data\n# X_train = np.array(training_td1[['trip_miles', 'trip_duration']])\n# X_train = X_train.reshape((X_train.shape[0], n_steps, n_features))\n# y_train = np.array(training_td1['driver_pay'])\n\n# Define the number of data points for training and testing\ntrain_size = 13000\ntest_size = 3000\n\n# Extract training data\nX_train = np.array(training_td1[['trip_miles', 'trip_duration']][:train_size])\nX_train = X_train.reshape((X_train.shape[0], n_steps, n_features))\ny_train = np.array(training_td1['driver_pay'][:train_size])\n\n# Extract test data\nX_test = np.array(target_td1[['trip_miles', 'trip_duration']][:test_size])\nX_test = X_test.reshape((X_test.shape[0], n_steps, n_features))\ny_test = np.array(target_td1['driver_pay'][:test_size])\n","metadata":{"execution":{"iopub.status.busy":"2024-04-10T05:02:58.337901Z","iopub.execute_input":"2024-04-10T05:02:58.338268Z","iopub.status.idle":"2024-04-10T05:02:58.429237Z","shell.execute_reply.started":"2024-04-10T05:02:58.338239Z","shell.execute_reply":"2024-04-10T05:02:58.428148Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"\n# Define the LSTM model\nlstm_model = Sequential([\n    LSTM(64, activation='relu', input_shape=(n_steps, n_features)),\n    Dense(32, activation='relu'),\n    Dense(1, activation='linear')\n])\n\n# Compile the model\nlstm_model.compile(optimizer='adam', loss='mean_squared_error')\n\n# Train the model\nlstm_model.fit(X_train, y_train, epochs=5)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T05:03:01.063805Z","iopub.execute_input":"2024-04-10T05:03:01.064574Z","iopub.status.idle":"2024-04-10T05:03:11.524325Z","shell.execute_reply.started":"2024-04-10T05:03:01.064542Z","shell.execute_reply":"2024-04-10T05:03:11.523216Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Epoch 1/5\n407/407 [==============================] - 3s 4ms/step - loss: 37.2754\nEpoch 2/5\n407/407 [==============================] - 2s 4ms/step - loss: 9.4672\nEpoch 3/5\n407/407 [==============================] - 2s 4ms/step - loss: 9.0384\nEpoch 4/5\n407/407 [==============================] - 2s 4ms/step - loss: 8.8090\nEpoch 5/5\n407/407 [==============================] - 2s 4ms/step - loss: 8.6619\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7944e5d13b80>"},"metadata":{}}]},{"cell_type":"code","source":"# predict driver pay per mile for the first 5 trips in the td1set.\nX_target = np.array(target_td1[['trip_miles', 'trip_duration']][:train_size])\nX_target = X_target.reshape((X_target.shape[0], n_steps, n_features))\npredictions_lstm = lstm_model.predict(X_target)\nprint(predictions_lstm[:5])\nprint(target_td1['driver_pay'][:5])","metadata":{"execution":{"iopub.status.busy":"2024-04-10T05:04:43.689113Z","iopub.execute_input":"2024-04-10T05:04:43.689843Z","iopub.status.idle":"2024-04-10T05:04:44.737783Z","shell.execute_reply.started":"2024-04-10T05:04:43.689807Z","shell.execute_reply":"2024-04-10T05:04:44.736794Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"407/407 [==============================] - 1s 2ms/step\n[[12.8559885]\n [ 7.5560913]\n [11.65605  ]\n [ 7.857862 ]\n [ 7.80001  ]]\n0    10.72\n1     5.40\n2     9.47\n3     5.40\n4     6.32\nName: driver_pay, dtype: float64\n","output_type":"stream"}]},{"cell_type":"code","source":"# Reshape the target data for evaluation\nX_target = np.array(target_td1[['trip_miles', 'trip_duration']][:train_size])\nX_target = X_target.reshape((X_target.shape[0], n_steps, n_features))\ny_target = np.array(target_td1['driver_pay'][:test_size])\n\n# Calculate predictions using the LSTM model\npredictions_lstm = lstm_model.predict(X_target)\n\n# Calculate evaluation metrics\nmse_lstm = mean_squared_error(y_target, predictions_lstm)\nmae_lstm = mean_absolute_error(y_target, predictions_lstm)\nr2_lstm = r2_score(y_target, predictions_lstm)\n\n# Print evaluation metrics\nprint(\"LSTM Model Evaluation:\")\nprint(\"Mean Squared Error (MSE):\", mse_lstm)\nprint(\"Mean Absolute Error (MAE):\", mae_lstm)\nprint(\"R-squared (R2) Score:\", r2_lstm)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T05:05:20.060406Z","iopub.execute_input":"2024-04-10T05:05:20.060801Z","iopub.status.idle":"2024-04-10T05:05:21.068788Z","shell.execute_reply.started":"2024-04-10T05:05:20.060770Z","shell.execute_reply":"2024-04-10T05:05:21.067394Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"407/407 [==============================] - 1s 2ms/step\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[30], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m predictions_lstm \u001b[38;5;241m=\u001b[39m lstm_model\u001b[38;5;241m.\u001b[39mpredict(X_target)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Calculate evaluation metrics\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m mse_lstm \u001b[38;5;241m=\u001b[39m \u001b[43mmean_squared_error\u001b[49m(y_target, predictions_lstm)\n\u001b[1;32m     11\u001b[0m mae_lstm \u001b[38;5;241m=\u001b[39m mean_absolute_error(y_target, predictions_lstm)\n\u001b[1;32m     12\u001b[0m r2_lstm \u001b[38;5;241m=\u001b[39m r2_score(y_target, predictions_lstm)\n","\u001b[0;31mNameError\u001b[0m: name 'mean_squared_error' is not defined"],"ename":"NameError","evalue":"name 'mean_squared_error' is not defined","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}